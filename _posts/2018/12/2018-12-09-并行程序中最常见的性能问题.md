---
layout:     post
title:      【译】并行程序中最常见的性能问题
subtitle:   并行 & 性能
date:       2018-12-11
author:     ChanChou
header-img: 
catalog: true
tags:
    - 并行
---

#【译】并行程序中最常见的性能问题
> 原文 [《Most Common Performance Issues in Parallel Programs》](https://blogs.msdn.microsoft.com/pfxteam/2008/08/12/most-common-performance-issues-in-parallel-programs/)<br/>
> 译者：[ChanChou](https://github.com/473278056)

# 并行程序中最常见的性能问题
- 由于Parallel Extensions的目标是简化并行编程，并行编程背后的动机是性能，因此我们收到的有关CTP版本的许多问题与性能相关并不奇怪。

- 开发人员会问为什么一个程序显示并行加速但另一个程序没有，或者如何修改程序以便在多核计算机上更好地扩展。

- 答案往往会有所不同。在某些情况下，观察到的问题是我们的代码库中一个相对容易修复的明显问题。在其他情况下，问题是并行扩展不能很好地适应特定的工作负载。这可能更难以解决，但了解实际工作负载是第一步，所以请继续向我们发送您的反馈意见。在另一类问题中，问题在于程序使用Parallel Extensions的方式，而我们几乎无法解决问题。

- 有趣的是，事实证明，无论问题的根源是在我们的代码中还是在用户代码中，都存在构成大多数性能问题的常见模式。在这篇博文中，我们将讨论在使用Parallel Extensions开发应用程序时要考虑的常见性能问题。

**可并行化的CPU绑定工作量** 

- 并行化的首要要求是程序必须具有可以并行执行的足够工作。如果只有一半的工作可以并行化，Amdahl定律规定我们不能将程序加速超过两倍。

- 此外，如果CPU是性能瓶颈，则抛出任务的其他CPU将最有帮助。如果程序花费90％的时间等待 服务器执行SQL查询，那么并行化程序可能不会带来显着的好处。（如果有多个请求可以发送给多个服务器，你可能仍会观察到加速。但是在这种情况下，异步编程模型可能会带来更好的性能。）

- 为了从并行性中受益，程序中处理器密集型工作的总量必须足够大，以使并行化的开销相形见绌，并且大部分工作必须可分解才能并行运行。

**任务粒度**

- 即使程序执行了大量可并行化的工作，我们也必须小心确保将工作分成适当大小的块，这些块将并行执行。如果我们创建了太多的块，那么管理和调度块的开销就会很大。如果我们创建的块太少，机器上的某些内核将无关紧要。

- 在Parallel Extensions API的某些部分，例如Parallel.For和PLINQ，我们库中的代码负责决定适当的任务粒度。在API的其他部分，例如任务和期货，它是用户代码的责任。无论谁负责创建任务，适当的任务粒度对于实现良好的性能都很重要。

**负载均衡**

- 即使有足够的可并行化CPU工作来使并行性变得有价值，我们也需要确保工作在机器上的核心之间均匀分布。由于不同的“工作块”在执行它们所需的时间上可能存在很大差异，因此这很复杂。此外，在执行完成之前，我们通常不知道每个块需要多少工作。

- 例如，如果Parallel.For假设循环的所有迭代花费相同的时间，我们可以简单地将范围划分为与核心一样多的连续范围，并将每个范围分配给一个核心。遗憾的是，由于每次迭代的工作可能会有所不同，因此有可能一个核心最终会进行许多昂贵的迭代，而其他核心的工作量则较少。在极端情况下，一个核心最终可能会完成所有工作，我们又回到顺序案例中。

- 幸运的是，我们的Parallel.For实现提供了适用于大多数工作负载的负载平衡。但是，在编写自己的并发代码时，您可能会遇到负载平衡问题。

**内存分配和垃圾收集**

- 有些程序在内存分配和垃圾收集方面花费了大量时间。例如，操作字符串的程序往往会分配大量内存，特别是如果它们没有经过精心设计以防止不必要的分配。

- 不幸的是，分配内存是一种可能需要同步的操作。毕竟，我们需要确保不同线程分配的内存区域不会重叠。

- 或许更严重的是，分配大量内存通常意味着我们还需要进行大量垃圾收集工作来回收已释放的内存。如果垃圾收集主导程序的运行时间，则程序将仅与垃圾收集算法一起扩展。

- 可以通过打开服务器GC来缓解此问题。有关服务器GC如何工作以及如何启用它的更多信息，请参阅Chris Lvon的博客文章[Server，Workstation and Concurrent GC](https://blogs.msdn.microsoft.com/clyon/archive/2004/09/08/226981.aspx "Server, Workstation and Concurrent GC")。

**虚假缓存线共享**

- 为了解释并行程序的这个特定性能问题，让我们快速回顾一下有关缓存如何在当今主流计算机上运行的一些细节。当CPU从主存储器读取值时，它会将值复制到缓存，以便后续访问该值的速度要快得多。事实上，CPU不仅会将特定值引入缓存，还会引入附近的内存位置。事实证明，如果程序读取特定的内存位置，那么它也可能会读取附近的值。因此，值 在主内存和缓存之间移动，称为缓存行，通常大小为64或128字节。

- 在具有多个核心的机器上出现的一个问题是，如果一个核心使特定存储器位置无效，则由另一个核心缓存的该存储器位置的版本变得无效。然后，具有无效缓存副本的核心必须在下次读取该内存位置时一直到主内存。因此，如果两个内核继续写入和读取特定的内存位置，它们可能最终会使对方的缓存无效，有时会大大降低程序的性能。

- 问题最棘手的部分是两个内核甚至不必写入相同的内存位置。如果它们写入同一缓存行上的两个内存位置（因此称为“虚假缓存行共享”），也会出现同样的问题。

- 奇怪的是，这个问题在实践中经常出现。例如，计算数组中整数之和的并行程序通常对每个线程都有一个单独的中间结果。中间结果可能是数组中的元素或类中的字段。并且，在这两种情况下，它们可能最终会在内存中结束。

- 有各种技术可以防止错误共享，或至少使其不太可能：使用垃圾数据填充数据结构，按照使错误共享的可能性较小的顺序分配它们，或者通过不同的线程分配它们。

**局部性问题**

- 有时修改程序以并行运行会对局部性产生负面影响。例如，假设我们想要对数组上的每个元素执行操作。在双核机器上，我们可以创建两个任务：一个用偶数索引对元素执行操作，一个用于处理奇数索引。

- 但是，作为负面结果，每个线程的引用局部性降低。线程需要访问的元素与它不关心的元素交织。每个高速缓存行将只包含一半的元素，这可能意味着两倍的内存访问将一直到主内存。

- 在这种特殊情况下，一种解决方案是将阵列分成左半部分和右半部分，而不是奇数和偶数元素。在更复杂的情况下，问题和解决方案可能不那么明显，因此并行化对参考局部性的影响是设计并行算法时要记住的事项之一。

**摘要** 

我们讨论了并发程序无法实现您期望的并行加速的最常见原因。如果您记住这些问题，您应该更容易设计和开发并行程序。

> 资料推荐 [Intel 官网](https://www.intel.com/content/www/us/en/homepage.html)